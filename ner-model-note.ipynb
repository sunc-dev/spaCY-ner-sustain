{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    },
    "colab": {
      "name": "ner-model-note.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunc-dev/spaCY-ner-sustain/blob/main/ner-model-note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltTvGHBDFZ9G"
      },
      "source": [
        "# <font size=\"10\">Custom entity recognition </font>\n",
        "## Model environment setup\n",
        "\n",
        "This notebook contains test code to train the implemented model in the generated training data outputted from\n",
        "the [ner-train notebook located here](./ner-train-note.ipynb).\n",
        "\n",
        "For simple loop model training (old), go [here](## Run training - using simple training loop from blank -- Old)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVojE79MFZ9H"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgTBkJsdFZ9H"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import warnings\n",
        "import json\n",
        "import ast\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "\n",
        "##SpaCy\n",
        "\n",
        "import en_core_web_sm\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.pipeline import Sentencizer\n",
        "from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.util import decaying\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4RRpdqkH_lT"
      },
      "source": [
        "# For Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrmzl2o-H9zW"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_t-LuqCFZ9M"
      },
      "source": [
        "## Import training data\n",
        "\n",
        "lets import the training data we generated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXFr8AiEFZ9M",
        "outputId": "0052e870-a551-403d-b72d-271b397932bd"
      },
      "source": [
        "train_path = r'./train/'\n",
        "\n",
        "csvs = glob.glob(train_path + \"/*.csv\")\n",
        "\n",
        "\n",
        "print('Filepath is :',(csvs))\n",
        "\n",
        "train_list = []\n",
        "\n",
        "for filename in csvs:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    train_list.append(df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filepath is : ./train/train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxUwACdFFZ9Q",
        "outputId": "db6ed986-f0c3-4568-b589-4746809d66b1"
      },
      "source": [
        "DATA = pd.concat(train_list, axis=0, ignore_index=True)\n",
        "DATA = DATA.drop_duplicates()\n",
        "DATA[0:10]\n",
        "print(len(DATA))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Comparison of Fuel Choice for \\nBackup Gener...</td>\n",
              "      <td>{'entities': [(33, 50, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A Comparison of Fuel Choice for \\nBackup Gener...</td>\n",
              "      <td>{'entities': [(33, 50, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A Comparison of Fuel Choice for \\nBackup Gener...</td>\n",
              "      <td>{'entities': [(33, 50, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Businesses are either considering installing b...</td>\n",
              "      <td>{'entities': [(45, 62, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This report discusses the costs and benefits o...</td>\n",
              "      <td>{'entities': [(48, 64, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>We discuss how to assign value to the reliabil...</td>\n",
              "      <td>{'entities': [(101, 118, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>At the same time, backup generators are not \\n...</td>\n",
              "      <td>{'entities': [(18, 35, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This makes backup generators best suited \\nfor...</td>\n",
              "      <td>{'entities': [(11, 28, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Regions with \\ncoincident peak charges, along ...</td>\n",
              "      <td>{'entities': [(161, 178, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>connected natural gas backup generators to eco...</td>\n",
              "      <td>{'entities': [(22, 39, 'SUSTECH')]}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  A Comparison of Fuel Choice for \\nBackup Gener...   \n",
              "1  A Comparison of Fuel Choice for \\nBackup Gener...   \n",
              "2  A Comparison of Fuel Choice for \\nBackup Gener...   \n",
              "3  Businesses are either considering installing b...   \n",
              "4  This report discusses the costs and benefits o...   \n",
              "5  We discuss how to assign value to the reliabil...   \n",
              "6  At the same time, backup generators are not \\n...   \n",
              "7  This makes backup generators best suited \\nfor...   \n",
              "8  Regions with \\ncoincident peak charges, along ...   \n",
              "9  connected natural gas backup generators to eco...   \n",
              "\n",
              "                                position  \n",
              "0    {'entities': [(33, 50, 'SUSTECH')]}  \n",
              "1    {'entities': [(33, 50, 'SUSTECH')]}  \n",
              "2    {'entities': [(33, 50, 'SUSTECH')]}  \n",
              "3    {'entities': [(45, 62, 'SUSTECH')]}  \n",
              "4    {'entities': [(48, 64, 'SUSTECH')]}  \n",
              "5  {'entities': [(101, 118, 'SUSTECH')]}  \n",
              "6    {'entities': [(18, 35, 'SUSTECH')]}  \n",
              "7    {'entities': [(11, 28, 'SUSTECH')]}  \n",
              "8  {'entities': [(161, 178, 'SUSTECH')]}  \n",
              "9    {'entities': [(22, 39, 'SUSTECH')]}  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9cYvMPJFZ9S",
        "outputId": "666f42dc-776d-4521-e33b-ef251ec754cb"
      },
      "source": [
        "#convert to list for model intake\n",
        "TRAIN_DATA = DATA.values.tolist()\n",
        "\n",
        "#for element in index 1 convert string (Entity position) to dictionary to be able to read by the model function\n",
        "for position in TRAIN_DATA:\n",
        "    position[1]=ast.literal_eval(position[1])\n",
        "    \n",
        "#Check our input list\n",
        "print(TRAIN_DATA[0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['A Comparison of Fuel Choice for \\nBackup Generators   \\n\\nSean Ericson and Dan Olis', {'entities': [(33, 50, 'SUSTECH')]}], ['A Comparison of Fuel Choice for \\nBackup Generators   \\n\\nSean Ericson and Dan Olis', {'entities': [(33, 50, 'SUSTECH')]}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbQYerDEFZ9V"
      },
      "source": [
        "## Run a test before training\n",
        "### Test existing default spacy model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJ4_q9SFZ9V",
        "outputId": "d52456b6-3a0e-4d0e-d857-d6349d6acab7"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.pipeline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x229098b5820>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x229095267c0>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x22909526580>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG06VFQ9FZ9b",
        "outputId": "6c6f11c6-b268-4d5d-d118-a5bfc345ba78"
      },
      "source": [
        "doc = nlp('Here is a green roof on this house. A green roof is good.')\n",
        "displacy.render(doc, style=\"ent\")\n",
        "# verified green roof does not match an entity in the NER"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\csunj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\spacy\\displacy\\__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  warnings.warn(Warnings.W006)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Here is a green roof on this house. A green roof is good.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD6c9-LPFZ9f"
      },
      "source": [
        "## TRAINING THE MODEL\n",
        "## Train model setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmFkte5ZFZ9f"
      },
      "source": [
        "### Define compounding batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aDY1Rp5FZ9g"
      },
      "source": [
        "def get_batches(train_data, model_type):\n",
        "    max_batch_sizes = {\"tagger\": 32, \"parser\": 16, \"ner\": 16, \"textcat\": 64}\n",
        "    max_batch_size = max_batch_sizes[model_type]\n",
        "    if len(train_data) < 1000:\n",
        "        max_batch_size /= 2\n",
        "    if len(train_data) < 500:\n",
        "        max_batch_size /= 2\n",
        "    batch_size = compounding(1, max_batch_size, 1.001)\n",
        "    batches = minibatch(train_data, size=batch_size)\n",
        "    return batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boH2r7RFFZ9j"
      },
      "source": [
        "#New training model loop to either accept existing model, if not model is not defined then create a blank nlp model using english vocab\n",
        "\n",
        "def train_model(**model_params):\n",
        "\n",
        "    model = model_params['model']\n",
        "    iterations = model_params['iterations']\n",
        "    train_data = model_params['train_data']\n",
        "    dropout = model_params['dropout']\n",
        "    \n",
        "    \n",
        "    random.seed(0)\n",
        "    \n",
        "    if model is not None:\n",
        "        nlp = spacy.load(model) #load existing spacy model\n",
        "        print(\"Loaded model '%s'\" % model)\n",
        "    else:\n",
        "        nlp = spacy.blank(\"en\")\n",
        "        print(\"Created blank 'en' model\")\n",
        "    \n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    # otherwise,get it, so we can add labels to it\n",
        "    else:\n",
        "        ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "    #ner.add_label(LABEL)  # add new entity label to entity recognizer\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations.get(\"entities\"):\n",
        "            ner.add_label(ent[2])\n",
        "            #print(ent[2])\n",
        "\n",
        "    # Adding extraneous labels shouldn't mess anything up\n",
        "    ner.add_label(\"VEGETABLE\")\n",
        "    move_names = list(ner.move_names)\n",
        "    # get names of other pipes to disable them during training\n",
        "    \n",
        "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "    \n",
        "    # only train NER\n",
        "    \n",
        "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
        "        # show warnings for misaligned entity spans once\n",
        "        \n",
        "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
        "\n",
        "        sizes=compounding(4.0, 32.0, 1.001)\n",
        "        # batch up the examples using spaCy's minibatch\n",
        "                  \n",
        "        if model is None:\n",
        "            optimizer = nlp.begin_training()\n",
        "        else:\n",
        "            optimizer = nlp.resume_training()\n",
        "\n",
        "        # reset and initialize the weights randomly – but only if we're\n",
        "        # training a new model\n",
        "        for itn in range(iterations):\n",
        "            random.shuffle(train_data)\n",
        "            #batches = get_batches(TRAIN_DATA, 'ner') resulted in poor loss\n",
        "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
        "            losses = {}\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, \n",
        "                           annotations,\n",
        "                           sgd=optimizer, \n",
        "                           drop = 0.1, \n",
        "                           losses=losses)\n",
        "            print(f\"Losses at iteration {itn} - {dt.datetime.now()} {losses}\")\n",
        "    \n",
        "    print('Model training completed')\n",
        "    return nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hZNCZF5FZ9l"
      },
      "source": [
        "model_params = {\n",
        "    'model': None,\n",
        "    'iterations': 30,\n",
        "    'train_data': TRAIN_DATA,\n",
        "    'dropout': decaying(0.6, 0.2, 1e-4)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUqwsny-FZ9n",
        "outputId": "dfa1cbc4-3f44-4dab-f8f7-183392b2c538"
      },
      "source": [
        "nlp = train_model(**model_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created blank 'en' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\csunj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\spacy\\language.py:635: UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th.\n",
            "  proc.begin_training(\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses at iteration 0 - 2020-10-27 10:52:56.484202 {'ner': 800.8414212201719}\n",
            "Losses at iteration 1 - 2020-10-27 10:53:06.224824 {'ner': 7.533502997782789}\n",
            "Losses at iteration 2 - 2020-10-27 10:53:17.922434 {'ner': 7.245988433990591}\n",
            "Losses at iteration 3 - 2020-10-27 10:53:28.529365 {'ner': 11.463132024309004}\n",
            "Losses at iteration 4 - 2020-10-27 10:53:40.717586 {'ner': 5.186865078675736}\n",
            "Losses at iteration 5 - 2020-10-27 10:53:51.362593 {'ner': 1.523608087809979}\n",
            "Losses at iteration 6 - 2020-10-27 10:54:02.307085 {'ner': 3.0806059114671296}\n",
            "Losses at iteration 7 - 2020-10-27 10:54:17.089014 {'ner': 1.040647210005701e-08}\n",
            "Losses at iteration 8 - 2020-10-27 10:54:30.373195 {'ner': 2.6109129437929435e-08}\n",
            "Losses at iteration 9 - 2020-10-27 10:54:44.277446 {'ner': 7.540048324779354e-09}\n",
            "Losses at iteration 10 - 2020-10-27 10:54:59.476116 {'ner': 0.00981159075042022}\n",
            "Losses at iteration 11 - 2020-10-27 10:55:13.385301 {'ner': 1.5563027785160132e-05}\n",
            "Losses at iteration 12 - 2020-10-27 10:55:27.254269 {'ner': 4.899298140491113e-10}\n",
            "Losses at iteration 13 - 2020-10-27 10:55:42.698309 {'ner': 3.2439231152683986e-07}\n",
            "Losses at iteration 14 - 2020-10-27 10:55:57.031054 {'ner': 3.585385485326166e-10}\n",
            "Losses at iteration 15 - 2020-10-27 10:56:11.029056 {'ner': 1.382067857542763e-09}\n",
            "Losses at iteration 16 - 2020-10-27 10:56:24.867099 {'ner': 2.216532734550198e-11}\n",
            "Losses at iteration 17 - 2020-10-27 10:56:40.691056 {'ner': 2.023261083941389e-10}\n",
            "Losses at iteration 18 - 2020-10-27 10:56:55.039138 {'ner': 3.9100765353994904e-11}\n",
            "Losses at iteration 19 - 2020-10-27 10:57:08.962101 {'ner': 2.553255698563762e-11}\n",
            "Losses at iteration 20 - 2020-10-27 10:57:24.479751 {'ner': 1.5717179616141997e-10}\n",
            "Losses at iteration 21 - 2020-10-27 10:57:40.022839 {'ner': 2.9720977139459907e-10}\n",
            "Losses at iteration 22 - 2020-10-27 10:57:55.585359 {'ner': 5.90041261220923e-11}\n",
            "Losses at iteration 23 - 2020-10-27 10:58:10.383186 {'ner': 2.118509832435402e-11}\n",
            "Losses at iteration 24 - 2020-10-27 10:58:24.008148 {'ner': 1.0125179305941299e-10}\n",
            "Losses at iteration 25 - 2020-10-27 10:58:37.616149 {'ner': 1.734349893907135e-11}\n",
            "Losses at iteration 26 - 2020-10-27 10:58:51.592185 {'ner': 1.5400016330202167e-11}\n",
            "Losses at iteration 27 - 2020-10-27 10:59:05.409154 {'ner': 8.620482366332182e-11}\n",
            "Losses at iteration 28 - 2020-10-27 10:59:20.565224 {'ner': 1.559052943724221e-10}\n",
            "Losses at iteration 29 - 2020-10-27 10:59:35.976750 {'ner': 2.8001840332319988e-11}\n",
            "Model training completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RenoBfkNFZ9p"
      },
      "source": [
        "## Test the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOfzjej7FZ9q",
        "outputId": "d4b8fe43-086f-4a31-fe99-193c9e8c5978"
      },
      "source": [
        "nlp.pipeline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x22978692d60>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YelALnlkFZ9u"
      },
      "source": [
        "doc = nlp('Here is a green roof on this house. A green roof is good. water piping, I have alot of battery packs')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tiR_oCMFZ9y",
        "outputId": "96133b28-3add-43bd-b5f3-12a73ca3ea4b"
      },
      "source": [
        "displacy.render(doc, style=\"ent\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Here is a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    green roof\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">SUSTECH</span>\n",
              "</mark>\n",
              " on this house. A \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    green roof\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">SUSTECH</span>\n",
              "</mark>\n",
              " is good. water piping, I have alot of battery packs</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gMfzK8kFZ90"
      },
      "source": [
        "## Save model for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZTl9AXjFZ91",
        "outputId": "8e5daf6f-3ad4-4d7a-ac45-16fb17ac7dd9"
      },
      "source": [
        "output_dir = r'./model'\n",
        "\n",
        "if output_dir is not None:\n",
        "    output_dir = Path(output_dir)\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    nlp.to_disk(output_dir)\n",
        "    print(\"Saved model to\", output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "almVk7DNFZ93"
      },
      "source": [
        "## Loading and testing the saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcaNNa6BFZ93",
        "outputId": "940ae120-af9b-4d4f-d524-157092c42d66"
      },
      "source": [
        "output_dir = r'./model'\n",
        "x = ['i am a green roof']\n",
        "print(\"Loading from\", output_dir)\n",
        "nlp2 = spacy.load(output_dir)\n",
        "\n",
        "for text in x:\n",
        "    doc = nlp2(text)\n",
        "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from ./model\n",
            "Entities [('green roof', 'SUSTECH')]\n",
            "Tokens [('i', '', 2), ('am', '', 2), ('a', '', 2), ('green', 'SUSTECH', 3), ('roof', 'SUSTECH', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27xZuIzFZ96"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}