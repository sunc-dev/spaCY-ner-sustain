{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    },
    "colab": {
      "name": "ner-model-note.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltTvGHBDFZ9G"
      },
      "source": [
        "# <font size=\"10\">Custom entity recognition </font>\n",
        "## Model environment setup\n",
        "\n",
        "This notebook contains test code to train the implemented model in the generated training data outputted from\n",
        "the [ner-train notebook located here](./ner-train-note.ipynb).\n",
        "\n",
        "For simple loop model training (old), go [here](## Run training - using simple training loop from blank -- Old)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVojE79MFZ9H"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jhBZ6QpwCq_",
        "outputId": "43196116-dcb9-4259-ea53-ac80ff01d118",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U spacy\n",
        "!pip install spacy[lookups]\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.3.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.3.1)\n",
            "Requirement already satisfied: spacy[lookups] in /usr/local/lib/python3.6/dist-packages (2.3.2)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (7.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (50.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]) (2.23.0)\n",
            "Collecting spacy-lookups-data<0.4.0,>=0.3.2; extra == \"lookups\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/b7/d5c635e51718c874606fb08249c0fab710286240d54847dc60bad3dfceac/spacy_lookups_data-0.3.2.tar.gz (93.8MB)\n",
            "\u001b[K     |████████████████████████████████| 93.8MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[lookups]) (2.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[lookups]) (3.3.1)\n",
            "Building wheels for collected packages: spacy-lookups-data\n",
            "  Building wheel for spacy-lookups-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-lookups-data: filename=spacy_lookups_data-0.3.2-py2.py3-none-any.whl size=93807573 sha256=219b3332a2f40191b7e27a829204135945318a57ba0a6858c3244e62b2ac4132\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/f4/d0/bf720a06127c95d9be2a81d197a3f1998ee5fc63410944e28f\n",
            "Successfully built spacy-lookups-data\n",
            "Installing collected packages: spacy-lookups-data\n",
            "Successfully installed spacy-lookups-data-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iIRtAeGPMVt",
        "outputId": "ea51261d-2d16-40ec-ff04-7ebec5b7e1d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m spacy download en\n",
        "\n",
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy validate"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.3.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: en_core_web_md==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz#egg=en_core_web_md==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.3.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "====================== Installed models (spaCy v2.3.2) ======================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.6/dist-packages/spacy\u001b[0m\n",
            "\n",
            "TYPE      NAME             MODEL            VERSION                            \n",
            "package   en-core-web-sm   en_core_web_sm   \u001b[38;5;2m2.3.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "package   en-core-web-md   en_core_web_md   \u001b[38;5;2m2.3.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "link      en               en_core_web_sm   \u001b[38;5;2m2.3.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgTBkJsdFZ9H"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import warnings\n",
        "import json\n",
        "import ast\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "\n",
        "##SpaCy\n",
        "\n",
        "import en_core_web_sm\n",
        "import en_core_web_md\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.pipeline import Sentencizer\n",
        "from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.util import decaying\n",
        "from spacy.pipeline import Tagger\n",
        "from spacy.pipeline import DependencyParser\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4RRpdqkH_lT"
      },
      "source": [
        "# For Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrmzl2o-H9zW",
        "outputId": "4663a7fe-cd22-4b44-b6cf-fce4bcdedb1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_t-LuqCFZ9M"
      },
      "source": [
        "## Import training data\n",
        "\n",
        "lets import the training data we generated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXFr8AiEFZ9M",
        "outputId": "f3939c99-0e9d-43ab-dd3c-c6f4c8dc3f4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_path = r'/content/drive/My Drive/Colab Notebooks/nlp-ner-sustain-notebook/train/'\n",
        "\n",
        "csvs = glob.glob(train_path + \"/*.csv\")\n",
        "\n",
        "\n",
        "print('Filepath is :',(csvs))\n",
        "\n",
        "train_list = []\n",
        "\n",
        "for filename in csvs:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    train_list.append(df)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filepath is : ['/content/drive/My Drive/Colab Notebooks/nlp-ner-sustain-notebook/train/trainset0.csv', '/content/drive/My Drive/Colab Notebooks/nlp-ner-sustain-notebook/train/trainset1.csv', '/content/drive/My Drive/Colab Notebooks/nlp-ner-sustain-notebook/train/trainset2.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxUwACdFFZ9Q",
        "outputId": "7382eca2-cd13-4f75-eb71-7bd722cd2983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "DATA = pd.concat(train_list, axis=0, ignore_index=True)\n",
        "DATA = DATA.drop_duplicates()\n",
        "DATA[0:10]\n",
        "print(len(DATA))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9cYvMPJFZ9S",
        "outputId": "c0dfb228-52dd-4f2b-f38a-c7f8368d67aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#convert to list for model intake\n",
        "TRAIN_DATA = DATA.values.tolist()\n",
        "\n",
        "#for element in index 1 convert string (Entity position) to dictionary to be able to read by the model function\n",
        "for position in TRAIN_DATA:\n",
        "    position[1]=ast.literal_eval(position[1])\n",
        "    \n",
        "#Check our input list\n",
        "print(TRAIN_DATA[0:2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['With increasing severe weather events and disasters \\ntriggering greater numbers of costly power outages, there is a growing interest in generators for \\nreliable backup power.', {'entities': [(161, 173, 'SUSTECH')]}], ['$3,153 \\n\\nNPC of Backup Power per Unit ($/kW)', {'entities': [(16, 28, 'SUSTECH')]}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbQYerDEFZ9V"
      },
      "source": [
        "## Run a test before training\n",
        "### Test existing default spacy model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJ4_q9SFZ9V",
        "outputId": "ba1c2972-ff3a-44fd-ddad-d516730dd873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = en_core_web_md.load()\n",
        "nlp.pipeline"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f14bd681400>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f14bd822648>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f14bd822588>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG06VFQ9FZ9b",
        "outputId": "07d6be82-7c7f-4b71-f620-1e83addf94cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "doc = nlp('Here is a green roof on this house. A green roof is good.')\n",
        "displacy.render(doc, style=\"ent\")\n",
        "# verified green roof does not match an entity in the NER"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/spacy/displacy/__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  warnings.warn(Warnings.W006)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Here is a green roof on this house. A green roof is good.</div>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD6c9-LPFZ9f"
      },
      "source": [
        "## TRAINING THE MODEL\n",
        "## Train model setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmFkte5ZFZ9f"
      },
      "source": [
        "### Define compounding batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aDY1Rp5FZ9g"
      },
      "source": [
        "def get_batches(train_data, model_type):\n",
        "    max_batch_sizes = {\"tagger\": 32, \"parser\": 16, \"ner\": 16, \"textcat\": 64}\n",
        "    max_batch_size = max_batch_sizes[model_type]\n",
        "    if len(train_data) < 1000:\n",
        "        max_batch_size /= 2\n",
        "    if len(train_data) < 500:\n",
        "        max_batch_size /= 2\n",
        "    batch_size = compounding(1, max_batch_size, 1.001)\n",
        "    batches = minibatch(train_data, size=batch_size)\n",
        "    return batches"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boH2r7RFFZ9j"
      },
      "source": [
        "#New training model loop to either accept existing model, if not model is not defined then create a blank nlp model using english vocab\n",
        "\n",
        "def train_model(**model_params):\n",
        "\n",
        "    model = model_params['model']\n",
        "    iterations = model_params['iterations']\n",
        "    train_data = model_params['train_data']\n",
        "    dropout = model_params['dropout']\n",
        "    \n",
        "    \n",
        "    random.seed(0)\n",
        "    \n",
        "    if model is not None:\n",
        "        nlp = model.load() #load existing spacy model\n",
        "        print(\"Loaded model '%s'\" % model)\n",
        "    else:\n",
        "        nlp = spacy.blank(\"en\")\n",
        "        #lang = \"en\"\n",
        "        #cls = spacy.util.get_lang_class(lang)   # 1. Get Language instance, e.g. English()\n",
        "        #nlp = cls() \n",
        "        print(\"Created blank 'en' model\")\n",
        "    \n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    # otherwise,get it, so we can add labels to it\n",
        "    else:\n",
        "        ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "    #ner.add_label(LABEL)  # add new entity label to entity recognizer\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations.get(\"entities\"):\n",
        "            ner.add_label(ent[2])\n",
        "            #print(ent[2])\n",
        "\n",
        "    # Adding extraneous labels shouldn't mess anything up\n",
        "    ner.add_label(\"VEGETABLE\")\n",
        "    move_names = list(ner.move_names)\n",
        "    # get names of other pipes to disable them during training\n",
        "    \n",
        "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "    \n",
        "    # only train NER\n",
        "    \n",
        "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
        "        # show warnings for misaligned entity spans once\n",
        "        \n",
        "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
        "\n",
        "        sizes=compounding(4.0, 32.0, 1.001)\n",
        "        # batch up the examples using spaCy's minibatch\n",
        "                  \n",
        "        if model is None:\n",
        "            optimizer = nlp.begin_training()\n",
        "        else:\n",
        "            optimizer = nlp.resume_training()\n",
        "\n",
        "        # reset and initialize the weights randomly – but only if we're\n",
        "        # training a new model\n",
        "        for itn in range(iterations):\n",
        "            random.shuffle(train_data)\n",
        "            #batches = get_batches(TRAIN_DATA, 'ner') resulted in poor loss\n",
        "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
        "            losses = {}\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, \n",
        "                           annotations,\n",
        "                           sgd=optimizer, \n",
        "                           drop = 0.2, \n",
        "                           losses=losses)\n",
        "            print(f\"Losses at iteration {itn} - {dt.datetime.now()} {losses}\")\n",
        "    \n",
        "    print('Model training completed')\n",
        "    return nlp"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hZNCZF5FZ9l"
      },
      "source": [
        "model_params = {\n",
        "    'model': None,\n",
        "    'iterations': 30,\n",
        "    'train_data': TRAIN_DATA,\n",
        "    'dropout': decaying(0.6, 0.2, 1e-4)\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUqwsny-FZ9n",
        "outputId": "2805e28e-1ba1-48ae-e3fd-319ae75c4f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = train_model(**model_params)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created blank 'en' model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/spacy/language.py:639: UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th.\n",
            "  **kwargs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Losses at iteration 0 - 2020-10-28 22:47:37.331359 {'ner': 1147.6173930254581}\n",
            "Losses at iteration 1 - 2020-10-28 22:47:57.982143 {'ner': 69.65919949273851}\n",
            "Losses at iteration 2 - 2020-10-28 22:48:18.257130 {'ner': 90.77040395048208}\n",
            "Losses at iteration 3 - 2020-10-28 22:48:40.431222 {'ner': 112.9496475175572}\n",
            "Losses at iteration 4 - 2020-10-28 22:49:03.230598 {'ner': 87.25429809784757}\n",
            "Losses at iteration 5 - 2020-10-28 22:49:25.961449 {'ner': 66.96094445663779}\n",
            "Losses at iteration 6 - 2020-10-28 22:49:49.121172 {'ner': 138.27960131744933}\n",
            "Losses at iteration 7 - 2020-10-28 22:50:12.124257 {'ner': 34.095706850456516}\n",
            "Losses at iteration 8 - 2020-10-28 22:50:35.106328 {'ner': 51.639370080827156}\n",
            "Losses at iteration 9 - 2020-10-28 22:50:58.342471 {'ner': 66.8501776199562}\n",
            "Losses at iteration 10 - 2020-10-28 22:51:24.801616 {'ner': 11.25965027327865}\n",
            "Losses at iteration 11 - 2020-10-28 22:52:10.123172 {'ner': 20.819562254195294}\n",
            "Losses at iteration 12 - 2020-10-28 22:52:54.274424 {'ner': 21.086618584377266}\n",
            "Losses at iteration 13 - 2020-10-28 22:53:32.073280 {'ner': 8.39429165510895}\n",
            "Losses at iteration 14 - 2020-10-28 22:54:08.655454 {'ner': 31.73360647313475}\n",
            "Losses at iteration 15 - 2020-10-28 22:54:34.273774 {'ner': 34.455571785960856}\n",
            "Losses at iteration 16 - 2020-10-28 22:55:08.449035 {'ner': 15.49722208159653}\n",
            "Losses at iteration 17 - 2020-10-28 22:55:50.902032 {'ner': 2.216709325814612}\n",
            "Losses at iteration 18 - 2020-10-28 22:56:39.836926 {'ner': 8.749188549173512}\n",
            "Losses at iteration 19 - 2020-10-28 22:57:27.816866 {'ner': 11.56789819787492}\n",
            "Losses at iteration 20 - 2020-10-28 22:58:24.947806 {'ner': 10.464780877559303}\n",
            "Losses at iteration 21 - 2020-10-28 22:59:17.413935 {'ner': 12.145233172288561}\n",
            "Losses at iteration 22 - 2020-10-28 23:00:12.504327 {'ner': 45.370013791040584}\n",
            "Losses at iteration 23 - 2020-10-28 23:01:09.388109 {'ner': 7.970899588223797}\n",
            "Losses at iteration 24 - 2020-10-28 23:01:48.329612 {'ner': 9.835723424803968}\n",
            "Losses at iteration 25 - 2020-10-28 23:02:27.914539 {'ner': 9.06727059512877}\n",
            "Losses at iteration 26 - 2020-10-28 23:03:20.423582 {'ner': 8.015422827945901}\n",
            "Losses at iteration 27 - 2020-10-28 23:04:10.250795 {'ner': 32.75188626081889}\n",
            "Losses at iteration 28 - 2020-10-28 23:04:56.120925 {'ner': 33.1117107480852}\n",
            "Losses at iteration 29 - 2020-10-28 23:05:22.905846 {'ner': 5.945734449826711}\n",
            "Model training completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RenoBfkNFZ9p"
      },
      "source": [
        "## Test the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOfzjej7FZ9q",
        "outputId": "3d061213-8744-4c35-d88c-3601fd2212cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp.pipeline"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f14bd822348>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oxbkbyzflek"
      },
      "source": [
        "\n",
        "tagger = Tagger(nlp.vocab)\n",
        "parser = DependencyParser(nlp.vocab)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sTGG9CliL7Z",
        "outputId": "cb237e6c-dc88-4d61-fdab-a0ce821f4856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "nlp.add_pipe(parser, before=\"ner\")\n",
        "nlp.add_pipe(tagger, before=\"parser\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2d85f633d6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, component, name, before, after, first, last)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_component_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE007\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE006\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E007] 'parser' already exists in pipeline. Existing names: ['parser', 'ner']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-yQg_LmiQkD",
        "outputId": "058f2d0b-f22f-47d4-d06a-cec1dbbc1ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp.pipeline"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f14b9b99468>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f14bd822348>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YelALnlkFZ9u"
      },
      "source": [
        "doc = nlp('Here is a green roof on this house. A green roof is good. water piping, I have alot of battery packs')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tiR_oCMFZ9y"
      },
      "source": [
        "displacy.render(doc, style=\"ent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gMfzK8kFZ90"
      },
      "source": [
        "## Save model for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZTl9AXjFZ91"
      },
      "source": [
        "output_dir = r'/content/drive/My Drive/Colab Notebooks/nlp-ner-sustain-notebook/model'\n",
        "\n",
        "if output_dir is not None:\n",
        "    output_dir = Path(output_dir)\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    nlp.to_disk(output_dir)\n",
        "    print(\"Saved model to\", output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "almVk7DNFZ93"
      },
      "source": [
        "## Loading and testing the saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcaNNa6BFZ93"
      },
      "source": [
        "x = ['i am a green roof']\n",
        "print(\"Loading from\", output_dir)\n",
        "nlp2 = spacy.load(output_dir)\n",
        "\n",
        "for text in x:\n",
        "    doc = nlp2(text)\n",
        "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27xZuIzFZ96"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIlynPFUiJyK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}